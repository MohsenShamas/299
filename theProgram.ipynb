{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Special(Enum):\n",
    "    BA2 = 1\n",
    "    EYE = 2\n",
    "    \n",
    "class Type(Enum):\n",
    "    PHRASE = 1\n",
    "    DIRECT = 2\n",
    "    START_SPECIAL_CHAR = 3\n",
    "    END_SPECIAL_CHAR = 4\n",
    "    SPECIAL_WORD = 5\n",
    "    STANDARD = 6\n",
    "    NO_WORD = 7\n",
    "\n",
    "# we will make one for each special beginning letter\n",
    "# TODO: MEHSEN\n",
    "class Ba2Cases(Enum):\n",
    "    PRESENT_LETTER = 1\n",
    "    PLACE_LETTER = 2\n",
    "    THING_LETTER = 3\n",
    "    \n",
    "# we will make one for each special end letter\n",
    "# TODO: MEHSEN\n",
    "class WawCases(Enum):\n",
    "    HIM_LETTER = 1\n",
    "    \n",
    "# we will make one for each special word\n",
    "# TODO: MEHSEN\n",
    "class SheCases(Enum):\n",
    "    SHAY2AN = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: MEHSEN\n",
    "#Fill these\n",
    "\n",
    "# map: \n",
    "# key is the beginning words of popular phrases\n",
    "# value is the possible dialect phrases\n",
    "startOfPhrases = {}\n",
    "\n",
    "# map:\n",
    "# key is the dialect phrase\n",
    "# value is the phrase in standard\n",
    "phrasesInjector = {}\n",
    "\n",
    "#set of start of phrases words\n",
    "startSet = set()\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# map of direct injections\n",
    "direct = {}\n",
    "\n",
    "#set of direct injection dialect words\n",
    "dialectSet = set()\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# map:\n",
    "# key is start special characters\n",
    "# value is a map:\n",
    "#     key is a case\n",
    "#     value is standard injection in such case\n",
    "startSpecialChar = {}\n",
    "\n",
    "#set of start special characters\n",
    "startSpecialCharSet = set()\n",
    "\n",
    "# map of start special characters and their corresponding action function\n",
    "startSpecialCharacterFunctions = {}\n",
    "# example: startSpecialCharacterFunctions[\"BA2\"] = actForBa2\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# map:\n",
    "# key is end special characters\n",
    "# value is a map:\n",
    "#     key is a case\n",
    "#     value is standard injection in such case\n",
    "endSpecialChar = {}\n",
    "\n",
    "#set of end special characters\n",
    "endSpecialCharSet = set()\n",
    "\n",
    "# map of end special characters and their corresponding action function\n",
    "endSpecialCharacterFunctions = {}\n",
    "# example: endSpecialCharacterFunctions[\"WAW\"] = actForWaw\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# map:\n",
    "# key is special word\n",
    "# value is a map:\n",
    "#     key is a case\n",
    "#     value is standard injection in such case\n",
    "specialWords = {}\n",
    "\n",
    "#set of special words\n",
    "specialWordsSet = set()\n",
    "\n",
    "# map of special words and their corresponding action function\n",
    "specialWordsFunctions = {}\n",
    "# example: specialWordsFunctions[\"SHE\"] = actForShe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "# phrases\n",
    "#--------------------------------------------------\n",
    "\n",
    "def startOfPhrasesChecker(word):\n",
    "    return True if word in startSet else False\n",
    "\n",
    "def getDialectPhraseFromStart(start):\n",
    "    return startOfPhrases[start]\n",
    "\n",
    "def getStandardPhraseFromDialect(phrase):\n",
    "    return phrasesInjector[phrase]\n",
    "\n",
    "# direct\n",
    "#--------------------------------------------------\n",
    "\n",
    "def checkInjection(word):\n",
    "    return True if word in dialectSet else False\n",
    "\n",
    "def getInjection(dialect):\n",
    "    return direct[dialect]\n",
    "\n",
    "# start special characters\n",
    "#--------------------------------------------------\n",
    "\n",
    "#TODO: TAZ\n",
    "def checkForStartSpecialCharacter(word):\n",
    "    specialChar = \"beginning char of word\"\n",
    "    return True if specialChar in startSpecialCharSet else False\n",
    "    \n",
    "#TODO: MEHSEN, make one for each start special character        \n",
    "def actForBa2(before_type, after_type, case_after):\n",
    "    if \"before_type is anything\" and \"after_type is verb\" and \"case_after is something\":\n",
    "        return startSpecialChar[\"BA2\"][Ba2Cases.PRESENT_LETTER]\n",
    "\n",
    "# end special characters\n",
    "#--------------------------------------------------\n",
    "\n",
    "#TODO: TAZ\n",
    "def checkForEndSpecialCharacter(word):\n",
    "    specialChar = \"end char of word\"\n",
    "    return True if specialChar in endSpecialCharSet else False\n",
    "    \n",
    "#TODO: MEHSEN, make one for each end special character        \n",
    "def actForWaw(before_type,after_type, case_before, case_after):\n",
    "    if \"before_type is thing\" and \"after_type is anything\" and \"case_before is something\" and \"case_after is something\":\n",
    "        return endSpecialChar[\"WAW\"][WawCases.HIM_LETTER]\n",
    "    \n",
    "# special words\n",
    "#--------------------------------------------------\n",
    "\n",
    "#TODO: TAZ\n",
    "def checkForSpecialWord(word):\n",
    "    return True if word in specialWordsSet else False\n",
    "    \n",
    "#TODO: MEHSEN, make one for each special word        \n",
    "def actForShe(before_type,after_type, case_after):\n",
    "    if \"before_type is verb\" and \"after_type is something\" and \"case_after is something\":\n",
    "        return specialWords[\"SHE\"][SheCases.SHAY2AN]\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#part of speech\n",
    "\n",
    "#TODO: TAZ ask MEHSEN\n",
    "def getPOS(word):\n",
    "    return word \n",
    "\n",
    "#TODO: TAZ ask MEHSEN\n",
    "def isModern(word):\n",
    "    return True if \"fosha\" else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program\n",
    "\n",
    "# takes text as string from website and return it standardized\n",
    "\n",
    "text = \"string\"\n",
    "\n",
    "text = pre_process(text)\n",
    "\n",
    "listOfSentences = splitTextIntoSentences(text)\n",
    "\n",
    "for s in range len(listOfSentences):\n",
    "    \n",
    "    listOfWords = splitSentencetIntoWords(listOfSentences[s])\n",
    "    \n",
    "    listAfterDirectInjections = injectIntoWords(listOfWords)\n",
    "\n",
    "    listOfStandardWords = change_words(listAfterDirectInjections)\n",
    "\n",
    "    listOfSentences[s] = \" \".join(listOfStandardWords)\n",
    "\n",
    "standard_text = \".\".join(listOfSentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TAZ\n",
    "# pre-process the text: remove movements, stressings, Hamzat -> | , push every alone char into the word in front of it\n",
    "def pre_process(TEXT):\n",
    "    return \"PRE PROCESSED TEXT\"\n",
    "\n",
    "# TODO: TAZ\n",
    "# split text into sentences on points for now\n",
    "def splitTextIntoSentences(TEXT):\n",
    "    return [\"sentence1\",\"sentence2\"]\n",
    "\n",
    "# TODO: TAZ\n",
    "# split sentence into words on spaces for now\n",
    "def splitSentencetIntoWords(sentence):\n",
    "    return [\"word1\",\"word2\"]\n",
    "\n",
    "def injectIntoWords(DIALECTS):\n",
    "    for d in range(len(DIALECTS)):\n",
    "        dialect = DIALECTS[d]\n",
    "        if checkInjection(dialect):\n",
    "            DIALECTS[d] = getInjection(dialect)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_words(DIALECTS):\n",
    "    for i in range(len(DIALECTS)):\n",
    "        word = DIALECTS[i]\n",
    "        case,steps = ACT_ON_WORD(i,word,DIALECTS)\n",
    "        #TODO: TAZ\n",
    "        #continue from steps after if steps > 0\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACT_ON_WORD(i,word,DIALECTS):\n",
    "    \n",
    "    if startOfPhrasesChecker(word):\n",
    "        possible_phrases = getDialectPhraseFromStart(word)\n",
    "        # TODO: TAZ\n",
    "        result_of_comparison = \"compare to possible phrases and return the found dialect phrase\"\n",
    "        if result_of_comparison != \"\":\n",
    "\n",
    "            standard_phrase = getStandardPhraseFromDialect(result_of_comparison)\n",
    "            \n",
    "            #TODO: TAZ\n",
    "            # be aware that dialect phrase and modern one may be of different lengths\n",
    "            # you have to replace in the list in a smart way like you\n",
    "            index = \"replace result_of_comparison by standard_phrase and return the index to continue from\"\n",
    "            return Type.PHRASE, index\n",
    "        \n",
    "        else:\n",
    "            print(\"problem in phrases: a phrase you dont know!!\", word)\n",
    "\n",
    "\n",
    "    if checkForStartSpecialCharacter(word):\n",
    "        special_char = \"get start special char from word\"\n",
    "        rest_of_word = \"get rest of word from word\"\n",
    "        \n",
    "        case_after = ACT_ON_WORD(i,rest_of_word,DIALECTS)\n",
    "        \n",
    "        if case_after != Type.NO_WORD:\n",
    "            before_type = getPOS(DIALECTS[i-1]) if i>0 else \"\"\n",
    "            after_type = getPOS(DIALECTS[i])\n",
    "            standard_special_char = startSpecialCharacterFunctions[special_char](before_type, after_type, case_after)\n",
    "            \n",
    "            #TODO: TAZ\n",
    "            #remark: dialects[i] is now a standard word withoud special character\n",
    "            index = \"replace dialects[i] with standard_special_char + dialects[i] and return the index to continue from\"\n",
    "            \n",
    "            return Type.START_SPECIAL_CHAR, index\n",
    "    \n",
    "    if checkForEndSpecialCharacter(word):\n",
    "        special_char = \"get end special char from word\"\n",
    "        rest_of_word = \"get rest of word from word\"\n",
    "        \n",
    "        case_before, steps_before = ACT_ON_WORD(i,rest_of_word,DIALECTS)\n",
    "        #leave steps for now\n",
    "        \n",
    "        if case_before != Type.NO_WORD:\n",
    "            case_after, steps_after = ACT_ON_WORD(i+1,DIALECTS[i],DIALECTS) if i<len(DIALECTS)-1 else (Type.NO_WORD, 0)\n",
    "            after_type = getPOS(DIALECTS[i+1]) if i<len(DIALECTS)-1 && (case_after!=Type.NO_WORD) else \"\"\n",
    "            before_type = getPOS(DIALECTS[i]) \n",
    "            standard_special_char = endSpecialCharacterFunctions[special_char](before_type, after_type, case_before, case_after)\n",
    "            \n",
    "            #TODO: TAZ\n",
    "            #remark: dialects[i] is now a standard word withoud special character\n",
    "            \"replace dialects[i] with dialects[i] + standard_special_char and return the index to continue from\"\n",
    "            \n",
    "            return Type.END_SPECIAL_CHAR, index\n",
    "    \n",
    "    if checkForSpecialWord(word):\n",
    "        \n",
    "        case_after, steps = ACT_ON_WORD(i+1,DIALECTS[i+1],DIALECTS) if i<len(DIALECTS)-1 else (Type.NO_WORD, 0)\n",
    "        #leave steps for now\n",
    "\n",
    "        if case != Type.NO_WORD:\n",
    "            before_type = getPOS(DIALECTS[i-1]) if i>0 else \"\"\n",
    "            after_type = getPOS(DIALECTS[i]) if i<len(DIALECTS)-1 && (case_after!=Type.NO_WORD) else \"\"\n",
    "            standard_special_char = startSpecialCharacterFunctions[special_char](before_type, after_type, case_after)\n",
    "            \n",
    "            #TODO: TAZ\n",
    "            \"replace dialects[i] with standard_special_word and return the index to continue from\"\n",
    "            return Type.START_SPECIAL_CHAR, index\n",
    "    \n",
    "    if isModern(word):\n",
    "        return Type.STANDARD, 0\n",
    "    \n",
    "    return Type.NO_WORD, 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
